From 904f10f24f152baeaa1986ecdbd6be837cce8848 Mon Sep 17 00:00:00 2001
From: Steve MacLean <sdmaclea.qdt@qualcommdatacenter.com>
Date: Tue, 12 Sep 2017 17:39:15 -0400
Subject: [PATCH] [Arm64] Swap compare operand if longer is second

---
 src/jit/lower.cpp | 17 +++++++++++++++--
 1 file changed, 15 insertions(+), 2 deletions(-)

diff --git a/src/jit/lower.cpp b/src/jit/lower.cpp
index 86c1c5a..e12b411 100644
--- a/src/jit/lower.cpp
+++ b/src/jit/lower.cpp
@@ -2346,7 +2346,7 @@ void Lowering::LowerCompare(GenTree* cmp)
     }
 #endif
 
-#ifdef _TARGET_AMD64_
+#ifdef _TARGET_64BIT_
     if (cmp->gtGetOp1()->TypeGet() != cmp->gtGetOp2()->TypeGet())
     {
         bool op1Is64Bit = (genTypeSize(cmp->gtGetOp1()->TypeGet()) == 8);
@@ -2367,7 +2367,11 @@ void Lowering::LowerCompare(GenTree* cmp)
 
             GenTree*  longOp       = op1Is64Bit ? cmp->gtOp.gtOp1 : cmp->gtOp.gtOp2;
             GenTree** smallerOpUse = op2Is64Bit ? &cmp->gtOp.gtOp1 : &cmp->gtOp.gtOp2;
+#ifdef _TARGET_AMD64_
             var_types smallerType  = (*smallerOpUse)->TypeGet();
+#elif defined(_TARGET_ARM64_)
+            var_types smallerType  = genActualType((*smallerOpUse)->TypeGet());
+#endif // _TARGET_AMD64_
 
             assert(genTypeSize(smallerType) < 8);
 
@@ -2379,6 +2383,7 @@ void Lowering::LowerCompare(GenTree* cmp)
             {
                 (*smallerOpUse)->gtType = TYP_LONG;
             }
+#ifdef _TARGET_AMD64_
             else
             {
                 GenTree* cast = comp->gtNewCastNode(TYP_LONG, *smallerOpUse, TYP_LONG);
@@ -2386,9 +2391,17 @@ void Lowering::LowerCompare(GenTree* cmp)
                 BlockRange().InsertAfter(cast->gtGetOp1(), cast);
                 ContainCheckCast(cast->AsCast());
             }
-        }
+#elif defined(_TARGET_ARM64_)
+            else if (op2Is64Bit && !longOp->IsCnsIntOrI())
+            {
+                // Arm64 can use extended compare if smaller register operand is second
+                cmp->SetOperRaw(GenTree::SwapRelop(cmp->OperGet()));
+                std::swap(cmp->gtOp.gtOp1, cmp->gtOp.gtOp2);
             }
 #endif // _TARGET_AMD64_
+        }
+    }
+#endif // _TARGET_64BIT_
 
 #if defined(_TARGET_XARCH_) || defined(_TARGET_ARM64_)
     if (cmp->gtGetOp2()->IsIntegralConst())
-- 
2.7.4

